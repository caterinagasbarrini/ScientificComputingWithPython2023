{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. **Text files**\n",
    "\n",
    "Perform the following operations on plain `txt` files:\n",
    "\n",
    "+ create a list of integrer numbers and then save it to a text file named `data_int.txt`. Run the `cat` command to print the content of the file.\n",
    "+ create a matrix of 5x5 floats and then save it to a text file named `data_float.txt`. Use the `cat` command to print the content of the file.\n",
    "+ load the `txt` file of the previous point and convert it to a `csv` file by hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "file_name = \"data_int.txt\"\n",
    "file = open(file_name, 'w') # opening a file in read only  mode\n",
    "lista = np.arange(10)\n",
    "file.write(str(lista))\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. **JSON files**\n",
    "\n",
    "Load the file `user_data.json`, which can be found at:\n",
    "\n",
    "- https://www.dropbox.com/s/sz5klcdpckc39hd/user_data.json\n",
    "\n",
    "and filter the data by the \"CreditCardType\" when it equals to \"American Express\". Than save the data to a new CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "\n",
    "data = json.load(open('user_data.json'))\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    " \n",
    "df = df[df['CreditCardType'] == \"American Express\"]\n",
    "#df.to_csv('user_data.csv')\n",
    "df.to_csv(r'American Express.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. **CSV files with Pandas**\n",
    "\n",
    "Load the file from this url:\n",
    "\n",
    "- https://www.dropbox.com/s/kgshemfgk22iy79/mushrooms_categorized.csv\n",
    "\n",
    "with Pandas. \n",
    "\n",
    "+ explore and print the DataFrame\n",
    "+ calculate, using `groupby()`, the average value of each feature, separately for each class\n",
    "+ save the file in a JSON format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: <class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "file = \"mushrooms_categorized.csv\"\n",
    "data =pd.read_csv(file)\n",
    "print(\"Type:\", type(data))\n",
    "\n",
    "classe0 = data.groupby('class').mean()\n",
    "\n",
    "\n",
    "js = classe0.to_json(orient=\"index\")\n",
    "\n",
    "save_file = open(\"mushrooms_categorized.json\", \"w\") \n",
    "\n",
    "json.dump(js, save_file, indent = 6)  \n",
    "save_file.close()  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4\\. **Reading a database**\n",
    "\n",
    "Get the database `sakila.db` from the lecture `06_dataio.ipynb`, and import the table `actors` as a Pandas dataframe. Using the dataframe, count how many actors have a first name that begins with `A`.\n",
    "\n",
    "*Hint:* use the Series `.str` method to apply the Python string methods to the elements of a Series, see [documentation](https://pandas.pydata.org/docs/reference/api/pandas.Series.str.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of actors with a first name starting with 'A' is: 13\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect('sakila.db')\n",
    "cur = conn.cursor()\n",
    "\n",
    "query = \"SELECT * FROM actor;\"\n",
    "actors_df = pd.read_sql_query(query, conn)\n",
    "\n",
    "\n",
    "conn.close()\n",
    "\n",
    "\n",
    "count_a_actors = actors_df[actors_df['first_name'].str.startswith('A', na=False)].shape[0]\n",
    "\n",
    "print(f\"The number of actors with a first name starting with 'A' is: {count_a_actors}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5\\. **Reading the credit card numbers**\n",
    "\n",
    "Get the binary file named `credit_card.dat` from this address:\n",
    "\n",
    "- https://www.dropbox.com/s/8m0syw2tkul3dap/credit_card.dat\n",
    "\n",
    "and convert the data into the real credit card number, knowing that:\n",
    "- each line corresponds to a credit card number, which consists of 16 characters (which are numbers in the 0-9 range) divided in 4 blocks, with a whitespace between each block\n",
    "- each character is written using a 6 bit binary representation (including the whitespace)\n",
    "- the final 4 bits of each line are a padding used to determine the end of the line, and can be ignored\n",
    "\n",
    "*Hint*: convert the binary numbers to the decimal representation first, and then use the `chr()` function to convert the latter to a char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('credit_card.dat', 'rb') as file:\n",
    "    bin_data = file.read()\n",
    "\n",
    "# Dividi il file binario in linee\n",
    "lines = bin_data.split(b'\\n')\n",
    "\n",
    "carta = []\n",
    "for line in lines:\n",
    "    if len(line) == 4:\n",
    "        break\n",
    "    line = line[:-4] #tolgo gli ultimi 4 caratteri \n",
    "    blocks = [line[i:i+6] for i in range(0, len(line), 6)] #divido la stringa in blocchi\n",
    "    decimals = [int(block, 2) for block in blocks]\n",
    "    characters = [chr(decimal) for decimal in decimals]\n",
    "    result = ''.join(characters)\n",
    "    carta.append(result)    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6\\. **Write data to a binary file**\n",
    "\n",
    "a) Start from the `data/data_000637.txt` file that we have used during the previous lectures, and convert it to a binary file according to the format defined below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from IPython.display import Image\n",
    "#Image(\"images/data_format.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Hints*:\n",
    "- Read the first 10 lines using Pandas\n",
    "- Iterate over the DataFrame rows\n",
    "- For every row, \"pack\" the values (features) into a single 64-bit word, according to the format specified above. Use bit-wise shifts and operators to do so.\n",
    "- Write each 64-bit word to a binary file. You can use `struct` in this way:\n",
    "```\n",
    "binary_file.write( struct.pack('<q', word) )\n",
    "```\n",
    "where `word` is the 64-bit word.\n",
    "- Close the file after completing the loop.\n",
    "\n",
    "b) Check that the binary file is correctly written by reading it with the code used in the lecture `06_dataio.ipynb`, and verify that the content of the `txt` and binary files is consistent.\n",
    "\n",
    "c) What is the difference of the size on disk between equivalent `txt` and binary files?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "datatxt = pd.read_csv('data_000637.txt', nrows=10)\n",
    "newfile = \"data_000637_new.dat\"\n",
    "\n",
    "binary_file = open(newfile, 'wb')\n",
    "for i in range(len(datatxt)):\n",
    "    word = (datatxt.iloc[i, 0] & 0x3) << 62\n",
    "    word = word | ((datatxt.iloc[i, 1] & 0xF) << 58)\n",
    "    word = word | ((datatxt.iloc[i, 2] & 0x1FF) << 49)\n",
    "    word = word | ((datatxt.iloc[i, 3] & 0xFFFFFFFF) << 17)\n",
    "    word = word | ((datatxt.iloc[i, 4] & 0xFFF) << 5)\n",
    "    word = word | (datatxt.iloc[i, 4] & 0x1F)\n",
    "    binary_file.write( struct.pack('<q', word) )\n",
    "binary_file.close()\n",
    "\n",
    "\n",
    "# Reading back and print the data to check the correspondence\n",
    "# with the actual values stored in the txt file\n",
    "columns = ['HEAD', 'FPGA', 'CHANNEL', 'ORBIT_CNT', 'BX_CNT', 'TDC_MEAS']\n",
    "df = pd.DataFrame({}, columns=columns)\n",
    "with open(newfile, 'rb') as file:\n",
    "    file_content = file.read()\n",
    "    word_counter = 0\n",
    "    word_size = 8 # size of the word in bytes\n",
    "    for i in range(0, len(file_content), word_size):\n",
    "        word_counter += 1\n",
    "        if word_counter > 10: break\n",
    "        word = struct.unpack('<q', file_content[i : i + word_size])[0] # get an 8-byte word\n",
    "        head     = (word >> 62) & 0x3\n",
    "        fpga     = (word >> 58) & 0xF\n",
    "        tdc_chan = (word >> 49) & 0x1FF\n",
    "        orb_cnt  = (word >> 17) & 0xFFFFFFFF\n",
    "        bx       = (word >> 5 ) & 0xFFF\n",
    "        tdc_meas = (word >> 0 ) & 0x1F\n",
    "        if i == 0: print ('{0}\\t{1}\\t{2}\\t{3}\\t{4}\\t{5}'.format('HEAD', 'FPGA', 'CHANNEL', 'ORBIT_CNT', 'BX_CNT', 'TDC_MEAS'))\n",
    "        print('{0}\\t{1}\\t{2}\\t{3}\\t{4}\\t{5}'.format(head, fpga, tdc_chan, orb_cnt, bx, tdc_meas))\n",
    "        entry = {'HEAD' : head, 'FPGA' : fpga, 'CHANNEL' : tdc_chan, 'ORBIT_CNT' : orb_cnt, 'BX_CNT' : bx, 'TDC_MEAS' : tdc_meas}\n",
    "        #df = df.append(entry, ignore_index=True)\n",
    "        data[word_counter] = entry\n",
    "        \n",
    "#The txt file has in mean 26 byte per row, while the binary packed dat file has 8 byte per row. For each row\n",
    "# the txt file occupies 18 bytes more than the dat file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
